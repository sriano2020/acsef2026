trainmeans_bw.csv")
# bg = pd.read_csv(r"C:\Users\prani\OneDrive\Documents\Visual Studio 2022\Science Fair\strainmeans_blood_glucose.csv")
# =========================================================
# Predict genetic strain from phenotype data (NO MERGING)
# Body weight + Blood glucose → genetic strain
# =========================================================

import pandas as pd
import numpy as np

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report


# =========================================================
# STEP 1: Load data
# =========================================================
print("Loading datasets...")

bw = pd.read_csv(r"C:\Users\prani\OneDrive\Documents\Visual Studio 2022\Science Fair\strainmeans_bw.csv")
bg = pd.read_csv(r"C:\Users\prani\OneDrive\Documents\Visual Studio 2022\Science Fair\strainmeans_blood_glucose.csv")

print("Body weight columns:")
print(bw.columns.tolist())

print("\nBlood glucose columns:")
print(bg.columns.tolist())


# =========================================================
# STEP 2: Confirm strain column exists
# =========================================================
if "strain" not in bw.columns:
    raise ValueError("ERROR: 'strain' column not found in body weight file.")

y = bw["strain"]
print("\nUsing genetics target: strain")


# =========================================================
# STEP 3: Select numeric phenotype features
# =========================================================
print("\nSelecting numeric phenotype features...")

bw = bw.select_dtypes(include=np.number)
bg = bg.select_dtypes(include=np.number)

if bw.empty:
    raise ValueError("ERROR: No numeric body weight features found.")

if bg.empty:
    raise ValueError("ERROR: No numeric blood glucose features found.")

print("Body weight features:", bw.columns.tolist())
print("Blood glucose features:", bg.columns.tolist())


# =========================
# STEP 4: Train / test split (aligned indices)
# =========================

# Use only rows that exist in BOTH datasets
n = min(len(bw), len(bg), len(y))
indices = np.arange(n)

X_bw = bw.iloc[:n].reset_index(drop=True)
X_bg = bg.iloc[:n].reset_index(drop=True)
y    = y.iloc[:n].reset_index(drop=True)

train_idx, test_idx = train_test_split(
    indices,
    test_size=0.2,
    random_state=42
)

X_bw_train = X_bw.iloc[train_idx]
X_bw_test  = X_bw.iloc[test_idx]

X_bg_train = X_bg.iloc[train_idx]
X_bg_test  = X_bg.iloc[test_idx]

y_train = y.iloc[train_idx]
y_test  = y.iloc[test_idx]


# =========================================================
# STEP 5: Scale each phenotype separately
# =========================================================
print("\nScaling features...")

scaler_bw = StandardScaler()
scaler_bg = StandardScaler()

X_bw_train = scaler_bw.fit_transform(X_bw_train)
X_bw_test  = scaler_bw.transform(X_bw_test)

X_bg_train = scaler_bg.fit_transform(X_bg_train)
X_bg_test  = scaler_bg.transform(X_bg_test)


# =========================================================
# STEP 6: Combine ONLY at model input
# =========================================================
X_train = np.hstack([X_bw_train, X_bg_train])
X_test  = np.hstack([X_bw_test, X_bg_test])


# =========================================================
# STEP 7: Train Random Forest model
# =========================================================
print("\nTraining model...")

model = RandomForestClassifier(
    n_estimators=300,
    random_state=42,
    class_weight="balanced"
)

model.fit(X_train, y_train)


# =========================================================
# STEP 8: Evaluate model
# =========================================================
print("\nEvaluating model...")

y_pred = model.predict(X_test)

print("\nAccuracy:", accuracy_score(y_test, y_pred))
print("\nClassification Report:")
print(classification_report(y_test, y_pred))


# =========================================================
# STEP 9: Feature importance
# =========================================================
feature_names = list(bw.columns) + list(bg.columns)

importances = pd.Series(
    model.feature_importances_,
    index=feature_names
).sort_values(ascending=False)

print("\nTop Feature Importances:")
print(importances.head(10))


# =========================
# STEP 10: Predict strain for new phenotype data (SAFE)
# =========================

print("\nPredicting strain for new sample...")

# Create a new sample using dataset feature means
new_bw = pd.DataFrame([X_bw.mean()], columns=X_bw.columns)
new_bg = pd.DataFrame([X_bg.mean()], columns=X_bg.columns)

new_bw_scaled = scaler_bw.transform(new_bw)
new_bg_scaled = scaler_bg.transform(new_bg)

X_new = np.hstack([new_bw_scaled, new_bg_scaled])

prediction = model.predict(X_new)

print("Predicted genetic strain:", prediction[0])

print("\nPIPELINE FINISHED SUCCESSFULLY ✅")
